{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "canvas": {
          "comments": [],
          "componentType": "CodeCell",
          "copiedOriginId": null,
          "diskcache": false,
          "headerColor": "transparent",
          "id": "63a8ca91-77f7-42a0-98ab-3da963b0ede7",
          "isComponent": false,
          "name": "",
          "parents": []
        },
        "id": "rsUHHHSC5FTb",
        "tags": []
      },
      "source": [
        "# Sentiment analysis pipeline with the transformers library"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Program\n",
        "\n",
        "- What is natural language processing and what are classification tasks. 😀\n",
        "- NLP tasks\n",
        "\n",
        "### Build a sentiment classifier\n",
        "- Load and explore your data\n",
        "- Text preprocessing\n",
        "- Load a model in the code environment\n",
        "- Step-by-step building a classifier with a pre-trained model\n",
        "- Run classification task: sentiment analysis on a data sample\n"
      ],
      "metadata": {
        "id": "IIy6Mm95FWPS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "canvas": {
          "comments": [],
          "componentType": "CodeCell",
          "copiedOriginId": null,
          "diskcache": false,
          "headerColor": "transparent",
          "id": "f4933072-dee2-4616-82c1-99f4fd97aea4",
          "isComponent": false,
          "name": "",
          "parents": []
        },
        "id": "RgIOFwK55FTd",
        "tags": []
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "canvas": {
          "comments": [],
          "componentType": "CodeCell",
          "copiedOriginId": null,
          "diskcache": false,
          "headerColor": "transparent",
          "id": "6916f834-04b9-4f75-a3bb-00709ef41168",
          "isComponent": false,
          "name": "",
          "parents": []
        },
        "id": "WPvYisky5FTd"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "We import transformers pipeline and torch\n",
        "'''\n",
        "\n",
        "from transformers import pipeline\n",
        "import torch\n",
        "from pprint import pprint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbyYvDbZ5FTe"
      },
      "source": [
        "\n",
        "## Natural language processing tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtNbt1G55FTe"
      },
      "source": [
        "### An example of previous generation of language model GPT-2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVhqe3ge5FTe"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Here we create our first pipeline with the library transformers\n",
        "'''\n",
        "\n",
        "from transformers import set_seed\n",
        "generator = pipeline('text-generation', model='gpt2')\n",
        "set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generator(\"I am a unicorn in a financial office,\", max_length=20, num_return_sequences=5)"
      ],
      "metadata": {
        "id": "hyMtHH-MHAsb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daeE5tVu5FTf"
      },
      "outputs": [],
      "source": [
        "generator(\"To bake cookies I need,\", max_length=25, num_return_sequences=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYMXofdS5FTf"
      },
      "outputs": [],
      "source": [
        "generator(\"I don't like cats,\", max_length=20, num_return_sequences=5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#generator(\"...\", max_length=.., num_return_sequences=..)"
      ],
      "metadata": {
        "id": "FE75v0f22sCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#generator()"
      ],
      "metadata": {
        "id": "1jWyYx5g2rJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NTg3GohV5FTg"
      },
      "source": [
        "### Labeling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eCwISgrI5FTg"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(model=\"facebook/bart-large-mnli\")"
      ]
    },
    {
      "source": [
        "results = classifier(\n",
        "    \"I have a problem with my iphone that needs to be resolved asap!!\",\n",
        "    candidate_labels=[\"urgent\", \"not urgent\", \"phone\", \"tablet\", \"computer\"],\n",
        ")\n",
        "\n",
        "for i, score in enumerate(results['scores']):\n",
        "  results['scores'][i] = round(score, 2)"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "GMU_9de_H-Jy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#show results:"
      ],
      "metadata": {
        "id": "JMIemf883B37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMmSZVL24twu"
      },
      "source": [
        "### Sentiment classification"
      ]
    },
    {
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "results = classifier(\"This conference is amazing!\")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "XOPGxHiiI8MT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#print results:"
      ],
      "metadata": {
        "id": "g06AV1b93Uw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#change the sentence and print the results:"
      ],
      "metadata": {
        "id": "-MKef4qC3uO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRaMacx45FTg"
      },
      "source": [
        "## Build a sentiment analysis classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjsXzxUC5FTg"
      },
      "source": [
        "### Instantiate a pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWxmAR205FTh"
      },
      "source": [
        "### Run the classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "canvas": {
          "comments": [],
          "componentType": "CodeCell",
          "copiedOriginId": null,
          "diskcache": false,
          "headerColor": "transparent",
          "id": "4780dc98-f54e-4e58-a994-aeed4be58112",
          "isComponent": false,
          "name": "",
          "parents": []
        },
        "id": "WKt4tOVY5FTh"
      },
      "outputs": [],
      "source": [
        "results = classifier(\"This is cool\")\n",
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "canvas": {
          "comments": [],
          "componentType": "CodeCell",
          "copiedOriginId": null,
          "diskcache": false,
          "headerColor": "transparent",
          "id": "0964179b-e8a5-45aa-a3b7-59128f8fa223",
          "isComponent": false,
          "name": "",
          "parents": []
        },
        "id": "KRXkyYPZ5FTh"
      },
      "source": [
        "### Multiple input"
      ]
    },
    {
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "results = classifier([\"I am happy\", \"I am sad\"])\n",
        "\n",
        "for result in results:\n",
        "  result['score'] = round(result['score'], 2)\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "QOIa5u1FJeNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#rewrite the code to instanciate a pipeline and classify two new sentences:"
      ],
      "metadata": {
        "id": "P7JiMDvq1yqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "canvas": {
          "comments": [],
          "componentType": "CodeCell",
          "copiedOriginId": null,
          "diskcache": false,
          "headerColor": "transparent",
          "id": "f079bdb6-56bf-4f1b-a14f-9f06e4bb716e",
          "isComponent": false,
          "name": "",
          "parents": []
        },
        "id": "WGctdQW95FTh"
      },
      "source": [
        "### Use a specific model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dFktvUTW_MMW"
      },
      "source": [
        "By default transformers library uses a distilbert model for the pipelines we have created. Let's change this and work with another model."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#First, explore this model card page and try some sentences: [link](https://huggingface.co/nlptown/bert-base-multilingual-uncased-sentiment)"
      ],
      "metadata": {
        "id": "Xt54UTlD5TKC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let's import this model into our code:"
      ],
      "metadata": {
        "id": "suVLYc03KPoL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AfP25uBVB0Jq"
      },
      "outputs": [],
      "source": [
        "model = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
        "second_classifier = pipeline(\"sentiment-analysis\", model=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1tEjaAyx4tww"
      },
      "outputs": [],
      "source": [
        "second_classifier(\"I am happy\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#what is different?"
      ],
      "metadata": {
        "id": "9apIWl6G5xiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import a new model\n",
        "#model = ..."
      ],
      "metadata": {
        "id": "3UGETPng5X9W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0_o6rh7DCo1"
      },
      "source": [
        "### Models cards\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6aqAdjFDGXt"
      },
      "source": [
        "Models cards provide information about the model, code examples, demos and most of the time information about how the models has been trained."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "canvas": {
          "comments": [],
          "componentType": "CodeCell",
          "copiedOriginId": null,
          "diskcache": false,
          "headerColor": "transparent",
          "id": "333402f2-aff3-40df-a760-df4eaea2ac72",
          "isComponent": false,
          "name": "",
          "parents": []
        },
        "id": "utfVEDXE5FTi"
      },
      "source": [
        "## Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZg6UtLt6-AJ"
      },
      "source": [
        "### What is a tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "canvas": {
          "comments": [],
          "componentType": "CodeCell",
          "copiedOriginId": null,
          "diskcache": false,
          "headerColor": "transparent",
          "id": "40adb757-7599-4416-b922-7da1860b29e8",
          "isComponent": false,
          "name": "",
          "parents": []
        },
        "id": "VkFbqwnz5FTi"
      },
      "source": [
        "- Tokenization is the process of breaking down text into smaller **units** called **tokens**. In order to process text the computer needs first to transform it into numbers.\n",
        "\n",
        "- Tokens are the basic building blocks used by Transformers models to understand and process text.\n",
        "\n",
        "- Tokens can represent **words, subwords, or even individual characters**, depending on the model's vocabulary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6PKD_vN7OAs"
      },
      "source": [
        "### Instanciate a tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "canvas": {
          "comments": [],
          "componentType": "CodeCell",
          "copiedOriginId": null,
          "diskcache": false,
          "headerColor": "transparent",
          "id": "35a540c1-e743-441b-890f-0df2bf11ffef",
          "isComponent": false,
          "name": "",
          "parents": []
        },
        "id": "6eNtRvg_5FTj"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "model = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "canvas": {
          "comments": [],
          "componentType": "CodeCell",
          "copiedOriginId": null,
          "diskcache": false,
          "headerColor": "transparent",
          "id": "15188336-ee64-426c-bcb3-5c701eea1ffb",
          "isComponent": false,
          "name": "",
          "parents": []
        },
        "id": "ojFjw6rA5FTk"
      },
      "source": [
        "We add our tokenizer to our pipeline:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "canvas": {
          "comments": [],
          "componentType": "CodeCell",
          "copiedOriginId": null,
          "diskcache": false,
          "headerColor": "transparent",
          "id": "c05116ad-ab33-4653-8356-70c120165492",
          "isComponent": false,
          "name": "",
          "parents": []
        },
        "id": "rpC1XsvH5FTk"
      },
      "outputs": [],
      "source": [
        "new_classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IxEIP0bc4tw7"
      },
      "outputs": [],
      "source": [
        "new_classifier(\"I am happy\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "canvas": {
          "comments": [],
          "componentType": "CodeCell",
          "copiedOriginId": null,
          "diskcache": false,
          "headerColor": "transparent",
          "id": "bd6f3686-1273-4f27-b309-3c0ff8b08b99",
          "isComponent": false,
          "name": "",
          "parents": []
        },
        "id": "z0CxZWPU5FTk"
      },
      "source": [
        "\n",
        "## Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GP63khbfNuig"
      },
      "source": [
        "A token is a value extracted from a **vocabulary list**.\n",
        "\n",
        "A vocabulary list is a set words."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wG-U84bRPonH"
      },
      "source": [
        "## Create tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HciDfEi5OWB4"
      },
      "source": [
        "### Split method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOCl31MHQmLh"
      },
      "outputs": [],
      "source": [
        "tokenized_text = \"We are at a hacking conference.\".split()\n",
        "print(tokenized_text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenize another sentence with split method."
      ],
      "metadata": {
        "id": "jClG678K6h44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzVXSUaUQKfO"
      },
      "source": [
        "### Use a tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JNiDhPFQ5Ty"
      },
      "outputs": [],
      "source": [
        "sequence = \"We are at a hacking conference.\"\n",
        "tokens = tokenizer.tokenize(sequence)\n",
        "\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#What is different?"
      ],
      "metadata": {
        "id": "515R9VKh6vFb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#create a new sequence and generate tokens for this sequence"
      ],
      "metadata": {
        "id": "uzFP5xxN6xKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDSsDdqT4tw8"
      },
      "source": [
        "### Try another tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJ5e8gL24tw8"
      },
      "outputs": [],
      "source": [
        "from transformers import XLNetTokenizer\n",
        "\n",
        "\n",
        "another_tokenizer = XLNetTokenizer.from_pretrained(\"xlnet/xlnet-base-cased\")\n",
        "new_tokens = another_tokenizer.tokenize(sequence)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Tokens: {new_tokens}\\n\")"
      ],
      "metadata": {
        "id": "MnLdnmfZN_Gk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#What is different?"
      ],
      "metadata": {
        "id": "c0yb96Tj6_4B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSsxoTMNPcfD"
      },
      "source": [
        "## Input IDs"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember our sentence : \"We are at a hacking conference.\" Let's see token ids for this sentence."
      ],
      "metadata": {
        "id": "aVYi1VdgOEab"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1l-HWXYnNFmi"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Our current tokens:\n",
        "Tokens: ['▁We', '▁are', '▁at', '▁a', '▁hacking', '▁conference', '.']\n",
        "'''\n",
        "\n",
        "ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "print(ids)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize another sentence and see the token ids:\n",
        "\n",
        "# your_sentence = \"\"\n",
        "# your_tokens =\n",
        "# your_ids ="
      ],
      "metadata": {
        "id": "QeUNbziZOuV5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "your_sentence = \"We are at a hackers party.\"\n",
        "your_tokens = tokenizer.tokenize(your_sentence)\n",
        "your_ids = tokenizer.convert_tokens_to_ids(your_tokens)"
      ],
      "metadata": {
        "id": "jLEwlaS8O_s7",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "print(your_tokens)\n",
        "print(your_ids)"
      ],
      "metadata": {
        "id": "ZjopjyP1Pg1W",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "canvas": {
          "comments": [],
          "componentType": "CodeCell",
          "copiedOriginId": null,
          "diskcache": false,
          "headerColor": "transparent",
          "id": "f5239f25-7e4b-4c33-8873-7b5ff3750f17",
          "isComponent": false,
          "name": "",
          "parents": []
        },
        "id": "tTJz32sE5FTk"
      },
      "source": [
        "## Padding and truncation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7m3AnlzKtz0"
      },
      "source": [
        "Language models work with **tensors**, we need them to be **the same length**.\n",
        "\n",
        "```\n",
        "padding=True and truncation=True\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "canvas": {
          "comments": [],
          "componentType": "CodeCell",
          "copiedOriginId": null,
          "diskcache": false,
          "headerColor": "transparent",
          "id": "615c6993-728e-4c6e-a8e6-c1604413bcbc",
          "isComponent": false,
          "name": "",
          "parents": []
        },
        "id": "YEmDTB6-5FTl"
      },
      "outputs": [],
      "source": [
        "sentences = [\"A white poney.\", \"A white poney in the garden.\"]\n",
        "\n",
        "batch = tokenizer(sentences, padding=True, truncation=True, max_length=512, return_tensors=\"pt\") #pt for pyTorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(batch)"
      ],
      "metadata": {
        "id": "FvWaPeNnQdGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#What are the ```'101'``` and ```'102'``` in the token list?\n"
      ],
      "metadata": {
        "id": "8woS-ayp8OWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#what are the zeros?"
      ],
      "metadata": {
        "id": "aLo3sz_q-NqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Try out with two new sentences"
      ],
      "metadata": {
        "id": "swgsN3Hc-RQw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "canvas": {
          "comments": [],
          "componentType": "CodeCell",
          "copiedOriginId": null,
          "diskcache": false,
          "headerColor": "transparent",
          "id": "f2626663-72ec-473b-81be-0ff012acc676",
          "isComponent": false,
          "name": "",
          "parents": []
        },
        "id": "8nJCnfwP5FTl"
      },
      "source": [
        "Note it returns a dictionary with keys ```'input_ids'``` and ```'attention_mask'```, with two tensors the 'input ids' tensor and the 'attention_mask' tensor.\n",
        "input_ids are unique ids."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqEFou5Jc7D2"
      },
      "source": [
        "# Dataset\n",
        "\n",
        "### How does a dataset looks like?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2O3wusvdB47"
      },
      "source": [
        "## Load a dataset from the hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eiaSZEoRdFdU"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"carblacac/twitter-sentiment-analysis\", split=\"train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L7o1PUV0fGnW"
      },
      "outputs": [],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWZbgPKTfOSv"
      },
      "source": [
        "The labels here are ```'feeling'```\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#find and load another dataset from huggingface hub: https://huggingface.co/\n",
        "#dataset2 ="
      ],
      "metadata": {
        "id": "zurK5pok8dON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#What are the labels in this one?"
      ],
      "metadata": {
        "id": "7aXFUM7D8wU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7XdMl4qh4Cu"
      },
      "outputs": [],
      "source": [
        "#back to our original dataset\n",
        "dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UTdVLXgSiG85"
      },
      "outputs": [],
      "source": [
        "sample = dataset[\"text\"][:10]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print the 22th tweet"
      ],
      "metadata": {
        "id": "GbsVfAqL86o0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHNbB6MQ4tw9"
      },
      "outputs": [],
      "source": [
        "dataset.info"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#How many tweets are in this dataset?\n",
        "#What is the title of the dataset?\n",
        "#When has it been published?"
      ],
      "metadata": {
        "id": "WAXpMCxU9WvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Convert the dataset to a pandas DataFrame\n",
        "df = pd.DataFrame(dataset)\n",
        "\n",
        "# Display the columns of the DataFrame\n",
        "print(df.columns)"
      ],
      "metadata": {
        "id": "wF-ODUpfSzX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenize the dataset"
      ],
      "metadata": {
        "id": "4ZBTJpEQUiau"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ioi2H8WFibyU"
      },
      "outputs": [],
      "source": [
        "tokenizer(dataset[0][\"text\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#what's new?"
      ],
      "metadata": {
        "id": "cTemS_UN98q2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dqYsLzcJitt-"
      },
      "outputs": [],
      "source": [
        "def tokenization(example):\n",
        "    return tokenizer(example[\"text\"])\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenization, batched=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DeNGwBDEkihq"
      },
      "outputs": [],
      "source": [
        "tokenized_dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#what can I say about this new dataset?"
      ],
      "metadata": {
        "id": "YLk-kM1A-sdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XChqgqei1JK"
      },
      "outputs": [],
      "source": [
        "tokenized_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"token_type_ids\", \"attention_mask\", \"feeling\"])\n",
        "tokenized_dataset.format['type']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#What did I just do? :)"
      ],
      "metadata": {
        "id": "ithQoA6p-3Db"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now your set is ready for training!"
      ],
      "metadata": {
        "id": "gnYhIYb2U3_A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create sample of the dataset"
      ],
      "metadata": {
        "id": "3mluJBpHUv8o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "cPdEOZXC--Eu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = dataset.to_pandas()\n",
        "sample = df.head(10)"
      ],
      "metadata": {
        "id": "of0vm5SXTPlL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample"
      ],
      "metadata": {
        "id": "u1RLyVfxTlRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "kOYXB6U8_35y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Show the first 4 tweets of this dataframe"
      ],
      "metadata": {
        "id": "M7IlXIanAA5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "df[:4]"
      ],
      "metadata": {
        "cellView": "form",
        "id": "XK9Qa4Uc_-ei"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Show only the labels for the first 4 tweets"
      ],
      "metadata": {
        "id": "e_N4zBsrAVbz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "df[:4]['feeling']"
      ],
      "metadata": {
        "cellView": "form",
        "id": "xa1T-l92AE3j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classify sentiment"
      ],
      "metadata": {
        "id": "PYZLjywuVCrn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "def predict_sentiment(text):\n",
        "  result = classifier(text)[0]\n",
        "  return result['label']\n",
        "\n",
        "sentiment = []\n",
        "for text in sample['text']:\n",
        "  sentiment.append(predict_sentiment(text))"
      ],
      "metadata": {
        "id": "bcdznEq3Sl-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample['predicted_sentiment'] = sentiment\n",
        "pprint(sentiment)"
      ],
      "metadata": {
        "id": "Y7Ni_TqPVQyf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#let's compare the predictions with the actual labels"
      ],
      "metadata": {
        "id": "CudwNHpxAgKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "![Pipeline](https://huggingface.co/datasets/huggingface-course/documentation-images/resolve/main/en/chapter2/full_nlp_pipeline.svg)"
      ],
      "metadata": {
        "id": "a9o6RurJKxyC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Thanks!\n",
        "\n",
        "## Questions ?"
      ],
      "metadata": {
        "id": "bGDd-QmBVrRn"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "z3CG2TMYVssg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "canvas": {
      "colorPalette": [
        "inherit",
        "inherit",
        "inherit",
        "inherit",
        "inherit",
        "inherit",
        "inherit",
        "inherit",
        "inherit",
        "inherit"
      ],
      "parameters": [],
      "version": "1.0"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}